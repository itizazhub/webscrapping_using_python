{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Webscraping Project\n",
    "#### (fetching products from ecommerce website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Class Scrapper For Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scrapper:\n",
    "    \n",
    "    base_url = \"https://www.urbansole.com.pk/collections/\"\n",
    "    links_pages = {'sport-shoes':1,'urbansole-footwear':5, 'women':1, 'kids':1, 'accessories':1, 'technology':1}\n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    dataset = {'Product_Name':[], 'Category':[], 'Price':[], 'Image_link':[], 'Product_link':[]}\n",
    "    images_directory_path = \"./Images\"\n",
    "    dataset_path = \"dataset.csv\"\n",
    "    url_first_part = \"https://www.urbansole.com.pk\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def fetch_products_urls(self) -> None:\n",
    "        for key, value in self.links_pages.items():\n",
    "            for page in range(1,value+1):\n",
    "                try:\n",
    "                    url = self.base_url+key+f\"?page={page}\"\n",
    "                    response =requests.get(url, headers=self.headers)\n",
    "                except Exception as e:\n",
    "                    print(\"URL Error: \", e)\n",
    "                if response.status_code==200:\n",
    "                    try:\n",
    "                        soup=BeautifulSoup(response.content, 'html.parser')\n",
    "                        items = soup.find_all('li', class_=\"productgrid--item\")\n",
    "                        for item in items:\n",
    "                            self.dataset['Product_link'].append(self.url_first_part+item.find('a', class_=\"productitem--image-link\").get('href'))\n",
    "                            self.dataset['Category'].append(key)\n",
    "                    except Exception as e:\n",
    "                        print(\"Soup Error: \", e)\n",
    "        print(\"URLs are fetched\")\n",
    "\n",
    "    def fetch_data_from_urls(self) -> None:\n",
    "        for product_link in self.dataset['Product_link']:\n",
    "            try:\n",
    "                response = requests.get(product_link, headers=self.headers)\n",
    "            except Exception as e:\n",
    "                print(\"URL Error\", e)\n",
    "            if response.status_code==200:\n",
    "                try:\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    self.dataset['Product_Name'].append(soup.find('h1', class_=\"product-title\").text.strip())\n",
    "                    self.dataset['Price'].append(soup.find('div', class_=\"price__current\").text.strip())\n",
    "                    div=soup.find('div', class_=\"product-gallery--image-background\")\n",
    "                    self.dataset['Image_link'].append('https:'+div.find('img').get('src'))\n",
    "                except Exception as e:\n",
    "                    print(f\"Soup Error : {e}\")\n",
    "            else:\n",
    "                print(\"page not found\")\n",
    "        print(\"Data is fetched\")\n",
    "\n",
    "    def download_images(self) -> None:\n",
    "        if not os.path.exists(self.images_directory_path):\n",
    "            os.makedirs(self.images_directory_path)\n",
    "        for Product_Name, image_url, Category in zip(self.dataset['Product_Name'],self.dataset['Image_link'],self.dataset['Category']):\n",
    "            path = os.path.join(self.images_directory_path, Category)+Product_Name+'.PNG'\n",
    "            try:\n",
    "                response = requests.get(image_url, headers=self.headers)\n",
    "            except Exception as e:\n",
    "                print(\"URL Error: \", e)\n",
    "            if response.status_code == 200:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "                image.save(path, 'PNG')\n",
    "            else:\n",
    "                print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "    \n",
    "    def save_dataset(self):\n",
    "        pd.DataFrame(self.dataset).to_csv(self.dataset_path, index=False)\n",
    "        print(\"Dataset is saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Object and Call Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper_obj = scrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs are fetched\n"
     ]
    }
   ],
   "source": [
    "scrapper_obj.fetch_products_urls() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is fetched\n"
     ]
    }
   ],
   "source": [
    "scrapper_obj.fetch_data_from_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is saved\n"
     ]
    }
   ],
   "source": [
    "scrapper_obj.save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper_obj.download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_link</th>\n",
       "      <th>Product_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rush US-EX-3204</td>\n",
       "      <td>sport-shoes</td>\n",
       "      <td>Rs.13,499</td>\n",
       "      <td>https://www.urbansole.com.pk/cdn/shop/files/US...</td>\n",
       "      <td>https://www.urbansole.com.pk/collections/sport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raptor US-EX-3206</td>\n",
       "      <td>sport-shoes</td>\n",
       "      <td>Rs.16,999</td>\n",
       "      <td>https://www.urbansole.com.pk/cdn/shop/files/US...</td>\n",
       "      <td>https://www.urbansole.com.pk/collections/sport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEN'S SPORTS SHOES US-EX-3203</td>\n",
       "      <td>sport-shoes</td>\n",
       "      <td>Rs.13,999</td>\n",
       "      <td>https://www.urbansole.com.pk/cdn/shop/files/US...</td>\n",
       "      <td>https://www.urbansole.com.pk/collections/sport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulse US-EX-3210</td>\n",
       "      <td>sport-shoes</td>\n",
       "      <td>Current price\\n\\nRs.9,799</td>\n",
       "      <td>https://www.urbansole.com.pk/cdn/shop/files/US...</td>\n",
       "      <td>https://www.urbansole.com.pk/collections/sport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fury US-EX-3208</td>\n",
       "      <td>sport-shoes</td>\n",
       "      <td>Rs.13,999</td>\n",
       "      <td>https://www.urbansole.com.pk/cdn/shop/files/US...</td>\n",
       "      <td>https://www.urbansole.com.pk/collections/sport...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Product_Name     Category                      Price  \\\n",
       "0                Rush US-EX-3204  sport-shoes                  Rs.13,499   \n",
       "1              Raptor US-EX-3206  sport-shoes                  Rs.16,999   \n",
       "2  MEN'S SPORTS SHOES US-EX-3203  sport-shoes                  Rs.13,999   \n",
       "3               Pulse US-EX-3210  sport-shoes  Current price\\n\\nRs.9,799   \n",
       "4                Fury US-EX-3208  sport-shoes                  Rs.13,999   \n",
       "\n",
       "                                          Image_link  \\\n",
       "0  https://www.urbansole.com.pk/cdn/shop/files/US...   \n",
       "1  https://www.urbansole.com.pk/cdn/shop/files/US...   \n",
       "2  https://www.urbansole.com.pk/cdn/shop/files/US...   \n",
       "3  https://www.urbansole.com.pk/cdn/shop/files/US...   \n",
       "4  https://www.urbansole.com.pk/cdn/shop/files/US...   \n",
       "\n",
       "                                        Product_link  \n",
       "0  https://www.urbansole.com.pk/collections/sport...  \n",
       "1  https://www.urbansole.com.pk/collections/sport...  \n",
       "2  https://www.urbansole.com.pk/collections/sport...  \n",
       "3  https://www.urbansole.com.pk/collections/sport...  \n",
       "4  https://www.urbansole.com.pk/collections/sport...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(scrapper_obj.dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, ['Product_Name', 'Category', 'Price', 'Image_link', 'Product_link'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zcf Images.tar.gz Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zcf dataset.tar.gz dataset.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
